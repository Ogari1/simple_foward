{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx93hGmSUloNlr0Lcr9AnE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ogari1/simple_foward/blob/main/Simple_foward.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TtzkVEd3YZn",
        "outputId": "08913172-d80d-43a4-8483-89ba6b79852b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Problem Statement:\n",
        "#The goal of this project is to create a feedforward neural network that can predict house prices based on various features, including the number of rooms, location, size, and other relevant factors.\n",
        "\n",
        "\n",
        "# Mount Google Drive in your Colab notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/house_prices/train.csv\")\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/house_prices/test.csv\")"
      ],
      "metadata": {
        "id": "kyvVgC0z4xIH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare the data:\n",
        "##Clean and preprocess the data\n",
        "train_data.fillna(-1, inplace=True)\n",
        "test_data.fillna(-1, inplace=True)"
      ],
      "metadata": {
        "id": "nDkRBg5L6Ce8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical features to strings\n",
        "cat_cols = train_data.select_dtypes(include=['object']).columns\n",
        "train_data[cat_cols] = train_data[cat_cols].astype(str)\n",
        "test_data[cat_cols] = test_data[cat_cols].astype(str)"
      ],
      "metadata": {
        "id": "W9LlMYer6GnT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables/features\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "encoded_features_train = one_hot_encoder.fit_transform(train_data[cat_cols]).toarray()\n",
        "encoded_features_test = one_hot_encoder.transform(test_data[cat_cols]).toarray()\n",
        "\n",
        "\n",
        "# Combine encoded features with numeric features\n",
        "numeric_cols = train_data.select_dtypes(include=['int64', 'float64']).drop(['Id', 'SalePrice'], axis=1).columns\n",
        "X_train = pd.concat([pd.DataFrame(encoded_features_train), train_data[numeric_cols].reset_index(drop=True)], axis=1)\n",
        "X_test = pd.concat([pd.DataFrame(encoded_features_test), test_data[numeric_cols].reset_index(drop=True)], axis=1)\n",
        "y_train = train_data['SalePrice']\n",
        "\n",
        "\n",
        "# Ensuring all feature names are strings\n",
        "X_train.columns = X_train.columns.astype(str)\n",
        "X_test.columns = X_test.columns.astype(str)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "8g-TXZAp6N6h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation=\"relu\"))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(32, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"linear\"))\n",
        "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n"
      ],
      "metadata": {
        "id": "XP6sKZot6njQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty6_zdBK7oua",
        "outputId": "3c79aa95-222d-486c-8c15-605208777a08"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "46/46 [==============================] - 1s 2ms/step - loss: 39036829696.0000\n",
            "Epoch 2/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 38949969920.0000\n",
            "Epoch 3/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 37972176896.0000\n",
            "Epoch 4/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 33584228352.0000\n",
            "Epoch 5/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 22908962816.0000\n",
            "Epoch 6/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 10058338304.0000\n",
            "Epoch 7/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 4837723648.0000\n",
            "Epoch 8/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 3360746496.0000\n",
            "Epoch 9/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 2649284096.0000\n",
            "Epoch 10/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 2283794688.0000\n",
            "Epoch 11/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 2057494400.0000\n",
            "Epoch 12/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1885025408.0000\n",
            "Epoch 13/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 1749379072.0000\n",
            "Epoch 14/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1628995840.0000\n",
            "Epoch 15/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1525778688.0000\n",
            "Epoch 16/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1436352768.0000\n",
            "Epoch 17/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 1357538944.0000\n",
            "Epoch 18/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1287020800.0000\n",
            "Epoch 19/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1223401344.0000\n",
            "Epoch 20/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1163145728.0000\n",
            "Epoch 21/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1114443776.0000\n",
            "Epoch 22/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 1066604352.0000\n",
            "Epoch 23/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 1020433664.0000\n",
            "Epoch 24/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 978439040.0000\n",
            "Epoch 25/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 949231168.0000\n",
            "Epoch 26/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 907987264.0000\n",
            "Epoch 27/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 878279744.0000\n",
            "Epoch 28/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 848631232.0000\n",
            "Epoch 29/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 822648640.0000\n",
            "Epoch 30/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 795076736.0000\n",
            "Epoch 31/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 771480256.0000\n",
            "Epoch 32/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 750115968.0000\n",
            "Epoch 33/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 728893248.0000\n",
            "Epoch 34/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 708156672.0000\n",
            "Epoch 35/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 689727744.0000\n",
            "Epoch 36/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 671472768.0000\n",
            "Epoch 37/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 655223232.0000\n",
            "Epoch 38/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 640558400.0000\n",
            "Epoch 39/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 624515456.0000\n",
            "Epoch 40/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 610567104.0000\n",
            "Epoch 41/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 596208384.0000\n",
            "Epoch 42/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 581032320.0000\n",
            "Epoch 43/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 568417280.0000\n",
            "Epoch 44/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 560494400.0000\n",
            "Epoch 45/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 545283968.0000\n",
            "Epoch 46/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 536920768.0000\n",
            "Epoch 47/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 522058304.0000\n",
            "Epoch 48/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 510364512.0000\n",
            "Epoch 49/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 500093184.0000\n",
            "Epoch 50/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 491515648.0000\n",
            "Epoch 51/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 483889088.0000\n",
            "Epoch 52/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 473296160.0000\n",
            "Epoch 53/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 462587616.0000\n",
            "Epoch 54/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 455386016.0000\n",
            "Epoch 55/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 446624256.0000\n",
            "Epoch 56/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 438510528.0000\n",
            "Epoch 57/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 430667488.0000\n",
            "Epoch 58/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 422898976.0000\n",
            "Epoch 59/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 415200064.0000\n",
            "Epoch 60/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 409227424.0000\n",
            "Epoch 61/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 403187424.0000\n",
            "Epoch 62/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 395905088.0000\n",
            "Epoch 63/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 388203712.0000\n",
            "Epoch 64/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 380975488.0000\n",
            "Epoch 65/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 376650848.0000\n",
            "Epoch 66/100\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 370495072.0000\n",
            "Epoch 67/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 365744960.0000\n",
            "Epoch 68/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 358746880.0000\n",
            "Epoch 69/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 352451744.0000\n",
            "Epoch 70/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 347479712.0000\n",
            "Epoch 71/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 343106432.0000\n",
            "Epoch 72/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 347734944.0000\n",
            "Epoch 73/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 335398016.0000\n",
            "Epoch 74/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 329915584.0000\n",
            "Epoch 75/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 328847136.0000\n",
            "Epoch 76/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 318977440.0000\n",
            "Epoch 77/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 318304704.0000\n",
            "Epoch 78/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 311640928.0000\n",
            "Epoch 79/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 311904192.0000\n",
            "Epoch 80/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 306229312.0000\n",
            "Epoch 81/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 300444896.0000\n",
            "Epoch 82/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 295827552.0000\n",
            "Epoch 83/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 295463008.0000\n",
            "Epoch 84/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 292836992.0000\n",
            "Epoch 85/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 292900224.0000\n",
            "Epoch 86/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 284394112.0000\n",
            "Epoch 87/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 284277024.0000\n",
            "Epoch 88/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 276276960.0000\n",
            "Epoch 89/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 274317536.0000\n",
            "Epoch 90/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 271308640.0000\n",
            "Epoch 91/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 270465696.0000\n",
            "Epoch 92/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 269275616.0000\n",
            "Epoch 93/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 264266336.0000\n",
            "Epoch 94/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 261150912.0000\n",
            "Epoch 95/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 255753776.0000\n",
            "Epoch 96/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 255958528.0000\n",
            "Epoch 97/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 253201552.0000\n",
            "Epoch 98/100\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 250352240.0000\n",
            "Epoch 99/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 244965088.0000\n",
            "Epoch 100/100\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 243519680.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a27cc21be50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDE_A_eD79QZ",
        "outputId": "4761d4e0-2504-4b5f-ae6a-52204aec1212"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: evaluate the model using a separate validation set\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "y_val_pred = model.predict(X_val)\n",
        "\n",
        "mse = mean_squared_error(y_val, y_val_pred)\n",
        "mae = mean_absolute_error(y_val, y_val_pred)\n",
        "r2 = r2_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}, Mean Absolute Error: {mae}, R-squared: {r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQ-H5Hxc8CHM",
        "outputId": "8fc72d57-d1b4-46c7-c5be-3cb3cdb9f158"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 225913680.0000\n",
            "Epoch 2/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 218023504.0000\n",
            "Epoch 3/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 214072480.0000\n",
            "Epoch 4/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 211974864.0000\n",
            "Epoch 5/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 208468224.0000\n",
            "Epoch 6/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 205459296.0000\n",
            "Epoch 7/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 204100288.0000\n",
            "Epoch 8/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 201010224.0000\n",
            "Epoch 9/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 200173392.0000\n",
            "Epoch 10/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 196308944.0000\n",
            "Epoch 11/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 198679040.0000\n",
            "Epoch 12/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 192683136.0000\n",
            "Epoch 13/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 190118288.0000\n",
            "Epoch 14/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 188261424.0000\n",
            "Epoch 15/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 187255680.0000\n",
            "Epoch 16/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 184740288.0000\n",
            "Epoch 17/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 185483728.0000\n",
            "Epoch 18/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 183133216.0000\n",
            "Epoch 19/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 180833248.0000\n",
            "Epoch 20/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 176555952.0000\n",
            "Epoch 21/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 177633792.0000\n",
            "Epoch 22/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 174863968.0000\n",
            "Epoch 23/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 172097968.0000\n",
            "Epoch 24/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 175576304.0000\n",
            "Epoch 25/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 170531824.0000\n",
            "Epoch 26/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 168121072.0000\n",
            "Epoch 27/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 168922032.0000\n",
            "Epoch 28/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 166860928.0000\n",
            "Epoch 29/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 164375520.0000\n",
            "Epoch 30/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 164028352.0000\n",
            "Epoch 31/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 161622720.0000\n",
            "Epoch 32/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 159416784.0000\n",
            "Epoch 33/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 156466800.0000\n",
            "Epoch 34/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 157013536.0000\n",
            "Epoch 35/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 153366016.0000\n",
            "Epoch 36/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 152629216.0000\n",
            "Epoch 37/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 155848800.0000\n",
            "Epoch 38/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 149719552.0000\n",
            "Epoch 39/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 149024208.0000\n",
            "Epoch 40/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 150483136.0000\n",
            "Epoch 41/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 147308768.0000\n",
            "Epoch 42/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 146552000.0000\n",
            "Epoch 43/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 146238640.0000\n",
            "Epoch 44/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 142806496.0000\n",
            "Epoch 45/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 140955136.0000\n",
            "Epoch 46/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 141002464.0000\n",
            "Epoch 47/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 140821664.0000\n",
            "Epoch 48/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 137840960.0000\n",
            "Epoch 49/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 136291728.0000\n",
            "Epoch 50/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 134787920.0000\n",
            "Epoch 51/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 137485680.0000\n",
            "Epoch 52/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 132927208.0000\n",
            "Epoch 53/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 130956768.0000\n",
            "Epoch 54/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 134560512.0000\n",
            "Epoch 55/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 130038336.0000\n",
            "Epoch 56/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 129704736.0000\n",
            "Epoch 57/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 130254088.0000\n",
            "Epoch 58/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 128469640.0000\n",
            "Epoch 59/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 126075664.0000\n",
            "Epoch 60/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 124171416.0000\n",
            "Epoch 61/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 123612816.0000\n",
            "Epoch 62/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 121230544.0000\n",
            "Epoch 63/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 120745352.0000\n",
            "Epoch 64/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 123603352.0000\n",
            "Epoch 65/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 122901688.0000\n",
            "Epoch 66/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 118772664.0000\n",
            "Epoch 67/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 117933352.0000\n",
            "Epoch 68/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 117616136.0000\n",
            "Epoch 69/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 116317312.0000\n",
            "Epoch 70/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 116802304.0000\n",
            "Epoch 71/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 113425360.0000\n",
            "Epoch 72/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 114847728.0000\n",
            "Epoch 73/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 113220832.0000\n",
            "Epoch 74/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 115617792.0000\n",
            "Epoch 75/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 110941248.0000\n",
            "Epoch 76/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 108318576.0000\n",
            "Epoch 77/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 108271712.0000\n",
            "Epoch 78/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 107298912.0000\n",
            "Epoch 79/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 107572808.0000\n",
            "Epoch 80/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 105775016.0000\n",
            "Epoch 81/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 106900912.0000\n",
            "Epoch 82/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 100695720.0000\n",
            "Epoch 83/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 105102544.0000\n",
            "Epoch 84/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 102460320.0000\n",
            "Epoch 85/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 99698888.0000\n",
            "Epoch 86/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 99835976.0000\n",
            "Epoch 87/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 100405536.0000\n",
            "Epoch 88/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 101664168.0000\n",
            "Epoch 89/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 99352840.0000\n",
            "Epoch 90/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 97494440.0000\n",
            "Epoch 91/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 95316816.0000\n",
            "Epoch 92/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 95287056.0000\n",
            "Epoch 93/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 94073936.0000\n",
            "Epoch 94/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 97736984.0000\n",
            "Epoch 95/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 95479320.0000\n",
            "Epoch 96/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 93595640.0000\n",
            "Epoch 97/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 90061616.0000\n",
            "Epoch 98/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 90975064.0000\n",
            "Epoch 99/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 89890032.0000\n",
            "Epoch 100/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 88646864.0000\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Mean Squared Error: 515517723.8909607, Mean Absolute Error: 15212.526166523972, R-squared: 0.9327906388899185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predicting House Prices with Machine Learning**\n",
        "\n",
        "The goal of thsi asiignment was to build a regression model that accurately predicts the sale prices of houses based on these attributes.\n",
        "\n",
        "Methods used:\n",
        "\n",
        "-Data Loading:\n",
        "First started by loading the dataset from CSV files.\n",
        "It contained two parts which were the training set and the test set.\n",
        "-Data Preprocessing:\n",
        "several preprocessing steps were performed to prepare the data for modelling which were:\n",
        "\n",
        "1)Handle Missing Values- where missing values were filled with -1 for both datasets.\n",
        "2)Categorical Data- categorical features were then converted to string data types to ensure proper encoding.\n",
        "3)One-Hot Encoding-one-hot encoding was then used to convert categorical variables into numerical features\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "\n",
        "-Data Standardization:\n",
        "Data was then standardized using the StandardScaler from Scikit-Learn To make sure all features had the same scale,\n",
        "python\n",
        "\n",
        "-Model Architecture:\n",
        "A neural network model was then created using the TensorFlow Keras API.\n",
        "\n",
        "-Model Training:\n",
        "The model was trained on the training data for 100 epochs with a batch size of 32 and the training data split into a validation set to evaluate model performance during training.\n",
        "\n",
        "-Model Evaluation:\n",
        "We evaluate the model was evaluated and the Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared (R²) calculated as performance metrics.\n",
        "\n",
        "-Model Prediction:\n",
        "Finally, house prices were predicted for the test dataset using the trained model.\n",
        "\n",
        "Findings and Recommendations:\n",
        "\n",
        "-The machine learning model effectively predicts house prices based on the provided features, showing relatively small errors and a strong predictive ability.\n",
        "-To make the model even better, you can adjust some settings and explore more ways to improve the features.\n",
        "-This method can also be used for other situations where you want to predict real estate prices with more data and different model setups.\n"
      ],
      "metadata": {
        "id": "3eFKQ0xugasa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WKbkrBV7jX8V"
      }
    }
  ]
}